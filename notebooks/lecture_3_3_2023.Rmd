---
title: "3/3/2023 Lecture"
output: html_notebook
---

```{r}
library(tidyverse)
library(MASS)
library(ISLR2)
library(caret)
library(FNN)
library(boot)
```

# Variation in MSE

See impact of the training data set size on the MSE. Have a large fixed, testing set, and try repeated training on data sets of varying sizes, $n$ . This is for data from

$$
Y = \beta_0 + \beta_1X + \epsilon
$$

Since the data is generated from a genuinely linear model, there is no model bias in linear regression. This will only show data variance and irreducible error.

```{r}
# reset seed
set.seed(100)

# training set size values
n_train <- c(5, 10,20, 40, 80)

# validation (testing) set is fixed
n_test <- 10^4

# set true coefficients
beta0_true = 2.
beta1_true = -1.5
# set noise parameters
eps = 1.

# construct validation set, fixed over the entire computation
x_test <-  runif(n_test,0,15)
y_test <-  beta0_true + beta1_true*x_test + eps * rnorm(length(x_test))
test.df <- data.frame("x"= x_test, "y"=y_test)

# number of samples per training set size
n_samples = 100

# these arrays begin as null but will be populated
MSE_vals <- NULL
n_vals <- NULL

# loop over each training set size n_samples times construct training
# data, train, compute the MSE, and record
for(j in 1:length(n_train)){
  for(i in 1:n_samples){
    n <- n_train[j]
    x <- runif(n,0,15)
    y <-  beta0_true + beta1_true*x + eps * rnorm(length(x))
    train.df <- data.frame("x"=x, "y"=y)
    lm.fit <- lm(y~x, data=train.df)

    # record the n and the MSE value at which this was computed
    n_vals <- append(n_vals,n)
    MSE_vals <- append(MSE_vals,mean((predict(lm.fit,test.df) -test.df$y)^2))
  }
}
# record as a data frame and post process
MSE.df = data.frame("n"=n_vals, "MSE"=MSE_vals)
MSE.df$n <- as.factor(MSE.df$n)

MSE.plt <- ggplot(MSE.df, aes(x=n, y=MSE_vals)) +geom_boxplot() +
  ggtitle("Mean Squared Error of a Linear Model",
          subtitle = sprintf("%d Test Sets of Size %d", n_samples, n_test)) +
  scale_y_log10()+
  labs(x="Training Set Size", y = "MSE") + theme_classic()
print(MSE.plt)
```

See variation in MSE from different testing/training set splits:

```{r}
set.seed(100)

# test/train sample size
n = 300
# number of splits
m = 5

maxp = 25

# preallocate an array with zeros
test.MSE.vals <- NULL
trial.vals <- NULL
p.vals <- NULL

# generate the entire data set
x <- runif(n,0,5)
y <- exp(x)*(1 + .5 * rnorm(n))
data.df <- tibble("x"=x, "y"=y)

# loop over data sets and polynomial fits
for (j in seq(m)){
  idx.train <- sample(seq(n), size = n/2)
  train.df <- data.df[idx.train,]
  test.df <- data.df[-idx.train,]
  # try all the polynomial fits on the testing data
  MSE =0
  for(p in seq(maxp)){
    lm.fit <- lm(y~poly(x,p), data=train.df)
    test.MSE.vals <- append(test.MSE.vals,mean((test.df$y - predict(lm.fit,test.df))^2))
    p.vals <- append(p.vals, p)
    trial.vals <- append(trial.vals, j)
  }
}

mse.df <- tibble(p=p.vals, MSE=test.MSE.vals, Trial=trial.vals)
mse.df$p <- as.integer(mse.df$p)
mse.df$Trial <- as.factor(mse.df$Trial)

val.plt <- ggplot(mse.df,mapping = aes(x=p, y=MSE, color=Trial)) +
  geom_line(lwd=2) +
  labs(x ="Degree of Polynomial", y = "MSE", title="50% Train-Test Data Split") +
  theme_classic()+scale_y_log10()
print(val.plt)
```

# Cross Validation

## LOOCV

`cv.glm` is part of part of `boot`, and it does the cross validation

```{r}
set.seed(100)

# test/train sample size
n = 10^2

maxp = 10

# preallocate an array with zeros
loocv.MSE.vals <- rep(0,maxp)

# generate the training set
x <- runif(n,0,5)
y <- exp(x)*(1 + .5 * rnorm(n))
train.df <- tibble("x"=x, "y"=y)

# loop over data sets and polynomial fits
for(p in seq(maxp)){
    glm.fit <- glm(y~poly(x,p), data=train.df)
    # run LOOCV cross validation
    cv.err <- cv.glm(train.df,glm.fit)
    # actual errors are stored in $delta[1]
    loocv.MSE.vals[p] <- cv.err$delta[1]
}
loocv.MSE.df <- tibble(p = seq(maxp), MSE=loocv.MSE.vals)
loocv.plt <- ggplot(loocv.MSE.df,mapping = aes(x=p, y=MSE)) +
  geom_line(lwd=2) +
  labs(x ="Degree Polynomial", y = "MSE", title="LOOCV MSE as a Function of Fit") +
  theme_classic()
print(loocv.plt)
```
